{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67611e55",
   "metadata": {},
   "source": [
    "#### Part 4: Textures\n",
    "\n",
    "**Previously**\n",
    "\n",
    "We explored sampling n-dimensional data one-point at a time to render it into a view. Along the way, we identified a few important sub-spaces that can be used to give the ability to control the view or manipulate data.\n",
    "\n",
    "GPUs don't exactly render things this way though. \n",
    "\n",
    "**In this part**\n",
    "\n",
    "What role does the GPU play in the rendering process? They are particularly good at resampling data, particularly from textures. Textures have restrictions on their dimensionality (2D or 3D for the most part), and shouldn't be too big.\n",
    "\n",
    "Here we'll work textures into the rendering workflow. These will be:\n",
    "\n",
    "* restricted to 2d\n",
    "* restricted in size\n",
    "* positioned in the view space using corner vertices\n",
    "* sampled into screen space\n",
    "\n",
    "The main idea is that a texture will correspond to some axis-aligned sub-volume copied to the \"GPU\" from a data source. The \"GPU\" will then sample the texture at the appropriate location in the view space.  The \"GPU\" class, in this case, is just our `View` object.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "889f2625",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# prelude\n",
    "from numpy import zeros,array,pi,cos,sin,eye,meshgrid,arange,cross\n",
    "from pylab import imshow,rand,figure,gca,axis,tight_layout,show\n",
    "from functools import reduce\n",
    "from typing import List\n",
    "from ipywidgets import interactive\n",
    "from matplotlib.patches import Rectangle, Polygon\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Makes 2d vecs in to affine 3d\n",
    "lift=lambda vs: array(list(map(lambda v: array([v[0],v[1],1]),vs.T))).T \n",
    "\n",
    "def xor_image(shape):\n",
    "    dims = meshgrid(*tuple([arange(dim) for dim in shape]))\n",
    "    return reduce(lambda acc, coord: acc ^ coord, dims)\n",
    "\n",
    "class Data:\n",
    "    def __init__(self, sz, view_dims=2):\n",
    "        self._data=zeros(sz)\n",
    "        self._ndim=len(sz)+1 # add 1 for affine\n",
    "        self._view_dims=view_dims\n",
    "        \n",
    "        self._transform=eye(self._ndim,view_dims+1)\n",
    "        self._transform[:,-1]=[0,0,0,1]\n",
    "        \n",
    "        self._data=0.04*xor_image(sz) # scale intensities\n",
    "                    \n",
    "    def slice(self,starts,stops,steps)->\"Data\":\n",
    "        slices = [slice(a,b,c) for a,b,c in zip(starts,stops,steps)]\n",
    "        data = self._data[tuple(slices)]\n",
    "        xform = self._transform.copy()\n",
    "        xform[:-1,-1]=[-s for s in starts]\n",
    "        d=Data(data.shape,self._view_dims)\n",
    "        d._data=data\n",
    "        d._transform=xform\n",
    "        return d\n",
    "    \n",
    "    def translate(self,dr):\n",
    "        d=Data(self._data.shape,self._view_dims)\n",
    "        d._data=self._data;\n",
    "        xform=self._transform.copy()\n",
    "        xform[:-1,-1]=-dr;\n",
    "        d._transform=xform\n",
    "        return d\n",
    "    \n",
    "    def rotate_and_other_stuff(self,theta_deg):\n",
    "        theta_rad=theta_deg*pi/180.0\n",
    "        c,s = cos(-theta_rad),sin(-theta_rad)\n",
    "        S = eye(4)\n",
    "        S[:3,:3]=S[:3,:3]*0.3\n",
    "        R = array([[c,-s,0,0],[s,c,0,0],[0,0,1,0],[0,0,0,1]])\n",
    "        xform = R @ S @ self._transform        \n",
    "        d=Data(self._data.shape,self._view_dims)\n",
    "        d._data=self._data;\n",
    "        d._transform=xform\n",
    "        return d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e374d356",
   "metadata": {},
   "source": [
    "Starting a bit from scratch here.  Lets try to define a more functional workflow.\n",
    "\n",
    "We'll need some information encapsulated in a View class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "155990df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class View:\n",
    "    def __init__(self, w, h):\n",
    "        self._size=[h,w]\n",
    "        self._bg=rand(self.h,self.w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582a513c",
   "metadata": {},
   "source": [
    "We also need some notion of a \"texture\".  In OpenGl, displaying an image involves some geometry and a texture. Barycentric coordinates are used to map texture coordinates that determine where the texture is sampled.\n",
    "\n",
    "Here I'll combine the geometry and the texture together into one thing. Instead of using barycentric coordinates, I'll use a linear transform to position the texture in the view space.\n",
    "\n",
    "You might notice that the `Tex2d` object here looks _very_ similar to the `Data` object from before. One conceptual difference is that `Tex2d` should be thought to \"own\" it's data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923a8b33",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e5e93744",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tex2d:\n",
    "    def __init__(self, w, h):\n",
    "        self._transform=eye(3)\n",
    "        self._data=zeros((h,w))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e57dd1",
   "metadata": {},
   "source": [
    "We need a way to sample the texture.  This involves some boundary handling. It accepts coordinates in \"texture space\".  In this case these are indices into the 2d array backing the texture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9bb316f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample2d(tex:Tex2d,r_tex):\n",
    "    def inbounds(r,sh):\n",
    "        # determine if r is inside the box described by sh \n",
    "        # (which is the w,h,d.. of the box)\n",
    "        v = all([0<=x<hi for x,hi in zip(r,sh)])\n",
    "        return v\n",
    "\n",
    "    if inbounds(r_tex,tex._data.shape):\n",
    "        return tex._data[tuple(r_tex)]\n",
    "    else: \n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92604bc7",
   "metadata": {},
   "source": [
    "Now we have what we need to define the render:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b0b643a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render(v:View, textures) -> array:\n",
    "    frame=v._bg.copy()\n",
    "\n",
    "    for y in range(0,frame.shape[0]):\n",
    "        for x in range(0,frame.shape[1]):\n",
    "            r_view=v._transform@[x,y,1] # screen space: 2d+1 to view\n",
    "            for tex in textures:\n",
    "                r_tex=tex._transform@r_view\n",
    "                v = sample2d(tex,r_tex)\n",
    "                if v is not None:\n",
    "                    frame[y,x]=v\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cd7df3",
   "metadata": {},
   "source": [
    "Very roughly, you can think of the projection to `r_view` as corresponding to what happens in the vertex shader stage. The projection to `r_tex` happens just before the fragment shader as part of the barycentric interpolation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b923417f",
   "metadata": {},
   "source": [
    "Ok, but where do we get these textures?\n",
    "\n",
    "They come from the data. We want to restrict things so resampling only happens during rendering - the texture needs to be an axis-aligned sub-volume of the data.\n",
    "\n",
    "There are all sorts of other interesting things we can dive into at this point, but lets just focus on querying the data set and loading the \"textures\".\n",
    "\n",
    "The textures we need to return should somehow be limited to the field of view. This will allow us to view data sets of unbounded size. So first we need to project the view area back to the data.  We can do this by projecting the vertices for the corners of the view. Using the transforms between the _screen_, _view_, and _data_ spaces defined before:\n",
    "\n",
    "$$\n",
    "r_{data}=T_{dv}T_{vs}r_{screen}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "31e5cb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "box_data shape: (4, 2)\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "\n",
    "def corners_to_box(cs):\n",
    "    return array([[cs[0,((i+1)&2)>>1],cs[1,(i&2)>>1]] for i in range(4)])\n",
    "\n",
    "# Prepare some data\n",
    "d=Data((64,48,33),view_dims=2)\n",
    "data=d.slice([10,10,0],[42,34,33],[1,1,1])\n",
    "data1=data.translate(array([0,0,0])).rotate_and_other_stuff(45)\n",
    "\n",
    "bbox_screen=array([[0,240],[0,320]])\n",
    "\n",
    "Tvs=eye(3) \n",
    "Tvs[:2,-1]=[50,0] # view space is translated relative to screen space for this example\n",
    "Tdv=data1._transform\n",
    "box_data=Tdv@Tvs@lift(corners_to_box(bbox_screen).T) # lift - makes 2xN into affine 3xN\n",
    "box_data=box_data[:2,:].T \n",
    "print('box_data shape:',box_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Draw the view box (green) \n",
    "# relative to the full data (gray) \n",
    "# and sliced subset (dark gray)\n",
    "\n",
    "figure()\n",
    "gca().add_collection(PatchCollection([\n",
    "    Rectangle((0,0),64,48),\n",
    "    Rectangle((10,10),42,24),\n",
    "    Polygon(box_data)\n",
    "],alpha=0.3,facecolors=['k','k','g']))\n",
    "axis('equal')\n",
    "tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63745e7",
   "metadata": {},
   "source": [
    "You can see that the green box intersects the grey ones non-orthogonally.\n",
    "\n",
    "However, the textures returned from the data sources (grey boxes) should be axis aligned.  They should also cover the visible area (gray intersection with green). What regions should be copied to texture?\n",
    "\n",
    "There are lots of good choices here. One way to do it is to find the intersection between these simple, convex polygons and then determine the minimal axis-aligned bounding box around that.\n",
    "\n",
    "Lets do something sillier, and pretend our data is chunked. This corresponds to picking a fixed texture size.  It's silly here because our chunk size is going to be very small. We'll only return the chunks that intersect the green area.\n",
    "\n",
    "We'll need an intersection test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "7d114e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "def hit(P,r):\n",
    "    def left_of(p,q,r):\n",
    "        return cross(q-p,r-p)>0\n",
    "    return all(left_of(P[p],P[q],r) for (p,q) in zip([0,1,2,3],[1,2,3,0]))\n",
    "\n",
    "print(hit(box_data,array([10,10]))) # miss\n",
    "print(hit(box_data,array([52,10]))) # hit\n",
    "print(hit(box_data,array([52,34]))) # miss\n",
    "print(hit(box_data,array([10,34]))) # miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c0c21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(data_source,cx,cy,query_polygon):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
